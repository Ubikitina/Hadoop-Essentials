{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "857b52f6-aeb3-4358-b8da-65421cc9a9bf",
   "metadata": {},
   "source": [
    "# HDFS distributed file system\n",
    "\n",
    "This Jupyter Notebook demonstrates basic HDFS operations, including creating a folder, uploading a file, and displaying its contents from HDFS.\n",
    "\n",
    "1. Create a local folder called tests-hdfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f1b30b5-f5e0-4a42-b8c1-504eb3208b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p /media/notebooks/tests-hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afe0673-2524-4ec0-9263-b0066559b2f0",
   "metadata": {},
   "source": [
    "2. Enter the folder you just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6194f1ce-29e7-435f-b0a9-96c0a745868c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/notebooks/tests-hdfs\n"
     ]
    }
   ],
   "source": [
    "# we move to the folder we have just created\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir(\"/media/notebooks/tests-hdfs\")\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e757494-fb63-46f0-84b4-e6e5dfcbfebd",
   "metadata": {},
   "source": [
    "3. Create a txt file locally, which you will call `my-first-file.txt`, containing a line with the following text: \"This is my first exercise of the course ‘Parallel Processing Ecosystem for Massive Data’\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2181b13e-870f-4160-a845-f72074616f5f",
   "metadata": {},
   "source": [
    "Option 1: Using echo command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2c2bb54-baf3-4db1-90a1-decad6fb6b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"This is my first exercise of the course 'Parallel Processing Ecosystem for Massive Data'\" >> my-first-file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e978c100-ab5c-4015-acf2-a4008c40cc4d",
   "metadata": {},
   "source": [
    "Option 2: Using `%%writefile` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44dc19a7-103f-40ad-b034-9ce6e42b9d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting my-first-file.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile my-first-file.txt\n",
    "This is my first exercise of the course \"Parallel Processing Ecosystem for Massive Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a76dd-c58c-453e-bc25-8aaff549eed7",
   "metadata": {},
   "source": [
    "4. Display the contents of the file with the command cat 'my-first-file.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "309a5f73-7a23-48ff-96d9-d8f580e29a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my first exercise of the course \"Parallel Processing Ecosystem for Massive Data\"\n"
     ]
    }
   ],
   "source": [
    "!cat my-first-file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef49569d-6c2d-4b2a-b8df-0a5c16494ec2",
   "metadata": {},
   "source": [
    "5. Create a folder in HDFS that you will call tests-hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3c537e9-1c0e-4d3a-a31c-31666d852818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "drwxr-xr-x   - root supergroup          0 2024-11-09 10:37 /curso\n",
      "drwxr-xr-x   - root supergroup          0 2024-11-09 11:01 /tests-hdfs\n",
      "drwxrwx---   - root supergroup          0 2024-11-09 09:57 /tmp\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -mkdir /tests-hdfs\n",
    "!hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c117410e-ba97-4e67-9b94-1c4802aab179",
   "metadata": {},
   "source": [
    "6. Upload the file previously created locally to the folder created in HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b458702-b273-43d0-b5e1-34078c08978f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   3 root supergroup         89 2024-11-09 11:02 /tests-hdfs/my-first-file.txt\n"
     ]
    }
   ],
   "source": [
    "# Upload the file to HDFS\n",
    "! hdfs dfs -put /media/notebooks/tests-hdfs/my-first-file.txt /tests-hdfs\n",
    "# Check if it has been uploaded correctly\n",
    "! hdfs dfs -ls /tests-hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a0e846-86a8-47f7-9eaa-5ff4ed7c27b6",
   "metadata": {},
   "source": [
    "7. Display file contents in HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "759dd143-9854-44b2-b440-18f9010cac99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my first exercise of the course \"Parallel Processing Ecosystem for Massive Data\"\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -cat /tests-hdfs/my-first-file.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
